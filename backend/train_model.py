# CÃ´ng dá»¥ng: Train model phÃ¢n loáº¡i topic vá»›i TF-IDF + Naive Bayes

import pandas as pd
import pickle
import os
from pathlib import Path
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
from underthesea import word_tokenize
import re

def clean_text(text):
    """LÃ m sáº¡ch vÄƒn báº£n"""
    # Chuyá»ƒn vá» chá»¯ thÆ°á»ng
    text = text.lower()
    # Loáº¡i bá» kÃ½ tá»± Ä‘áº·c biá»‡t, giá»¯ láº¡i chá»¯ cÃ¡i tiáº¿ng Viá»‡t
    text = re.sub(r'[^\w\sÃ¡Ã áº£Ã£áº¡Äƒáº¯áº±áº³áºµáº·Ã¢áº¥áº§áº©áº«áº­Ã©Ã¨áº»áº½áº¹Ãªáº¿á»á»ƒá»…á»‡Ã­Ã¬á»‰Ä©á»‹Ã³Ã²á»Ãµá»Ã´á»‘á»“á»•á»—á»™Æ¡á»›á»á»Ÿá»¡á»£ÃºÃ¹á»§Å©á»¥Æ°á»©á»«á»­á»¯á»±Ã½á»³á»·á»¹á»µÄ‘]', ' ', text)
    # Loáº¡i bá» khoáº£ng tráº¯ng thá»«a
    text = ' '.join(text.split())
    return text

def tokenize_text(text):
    """TÃ¡ch tá»« tiáº¿ng Viá»‡t"""
    try:
        tokens = word_tokenize(text, format="text")
        return tokens
    except:
        return text

def load_dataset(file_path):
    """Äá»c dataset"""
    print(f"ğŸ“‚ Äang Ä‘á»c dataset tá»«: {file_path}")
    df = pd.read_csv(file_path)
    print(f"âœ… ÄÃ£ Ä‘á»c {len(df)} máº«u")
    print(f"\nğŸ“Š PhÃ¢n bá»‘ topics:")
    print(df['topic'].value_counts())
    return df

def preprocess_data(df):
    """Tiá»n xá»­ lÃ½ dá»¯ liá»‡u"""
    print("\nğŸ§¹ Äang tiá»n xá»­ lÃ½ dá»¯ liá»‡u...")
    
    # LÃ m sáº¡ch vÄƒn báº£n
    df['text_clean'] = df['text'].apply(clean_text)
    
    # TÃ¡ch tá»« tiáº¿ng Viá»‡t
    print("âœ‚ï¸  Äang tÃ¡ch tá»« tiáº¿ng Viá»‡t (cÃ³ thá»ƒ máº¥t 1-2 phÃºt)...")
    df['text_tokenized'] = df['text_clean'].apply(tokenize_text)
    
    print("âœ… HoÃ n thÃ nh tiá»n xá»­ lÃ½")
    return df

def train_model(df):
    """Train model phÃ¢n loáº¡i"""
    print("\nğŸ¤– Báº®T Äáº¦U TRAIN MODEL.. .\n")
    
    # Chia train/test
    X = df['text_tokenized']
    y = df['topic']
    
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    
    print(f"ğŸ“Š Dá»¯ liá»‡u train: {len(X_train)} máº«u")
    print(f"ğŸ“Š Dá»¯ liá»‡u test: {len(X_test)} máº«u")
    
    # TF-IDF Vectorizer
    print("\nğŸ”¤ Äang táº¡o TF-IDF features...")
    vectorizer = TfidfVectorizer(
        max_features=5000,
        ngram_range=(1, 2),
        min_df=1,
        max_df=0.9
    )
    
    X_train_tfidf = vectorizer.fit_transform(X_train)
    X_test_tfidf = vectorizer.transform(X_test)
    
    print(f"âœ… TF-IDF shape: {X_train_tfidf.shape}")
    
    # Train Naive Bayes
    print("\nğŸ“ Äang train Multinomial Naive Bayes...")
    model = MultinomialNB(alpha=0.1)
    model.fit(X_train_tfidf, y_train)
    
    print("âœ… Train model hoÃ n thÃ nh!")
    
    # ÄÃ¡nh giÃ¡
    print("\nğŸ“ˆ ÄÃNH GIÃ MODEL:\n")
    
    # Accuracy
    y_pred = model.predict(X_test_tfidf)
    accuracy = accuracy_score(y_test, y_pred)
    print(f"ğŸ¯ Accuracy: {accuracy*100:.2f}%")
    
    # Classification report
    print("\nğŸ“Š Chi tiáº¿t theo tá»«ng topic:")
    print(classification_report(y_test, y_pred, zero_division=0))
    
    # Confusion Matrix
    print("\nğŸ”¢ Confusion Matrix:")
    cm = confusion_matrix(y_test, y_pred)
    print(cm)
    
    return model, vectorizer, accuracy

def save_model(model, vectorizer, output_dir='models'):
    """LÆ°u model vÃ  vectorizer"""
    print(f"\nğŸ’¾ Äang lÆ°u model...")
    
    # Táº¡o thÆ° má»¥c náº¿u chÆ°a cÃ³
    Path(output_dir).mkdir(exist_ok=True)
    
    # LÆ°u model
    model_path = Path(output_dir) / 'topic_classifier.pkl'
    with open(model_path, 'wb') as f:
        pickle.dump(model, f)
    print(f"âœ… Model Ä‘Ã£ lÆ°u táº¡i: {model_path}")
    
    # LÆ°u vectorizer
    vectorizer_path = Path(output_dir) / 'vectorizer.pkl'
    with open(vectorizer_path, 'wb') as f:
        pickle.dump(vectorizer, f)
    print(f"âœ… Vectorizer Ä‘Ã£ lÆ°u táº¡i: {vectorizer_path}")

def test_prediction(model, vectorizer):
    """Test thá»­ dá»± Ä‘oÃ¡n"""
    print("\nğŸ§ª TEST THá»¬ Dá»° ÄOÃN:\n")
    
    test_texts = [
        "Äá»™i tuyá»ƒn Viá»‡t Nam giÃ nh chiáº¿n tháº¯ng 2-0 trong tráº­n Ä‘áº¥u vÃ²ng loáº¡i World Cup hÃ´m qua",
        "GiÃ¡ vÃ ng hÃ´m nay tÄƒng máº¡nh do áº£nh hÆ°á»Ÿng cá»§a thá»‹ trÆ°á»ng tháº¿ giá»›i",
        "Apple vá»«a ra máº¯t iPhone má»›i vá»›i nhiá»u tÃ­nh nÄƒng cÃ´ng nghá»‡ Ä‘á»™t phÃ¡"
    ]
    
    for text in test_texts:
        # Tiá»n xá»­ lÃ½
        text_clean = clean_text(text)
        text_tokenized = tokenize_text(text_clean)
        
        # Vectorize
        text_tfidf = vectorizer. transform([text_tokenized])
        
        # Dá»± Ä‘oÃ¡n
        prediction = model.predict(text_tfidf)[0]
        proba = model.predict_proba(text_tfidf)[0]
        
        # Láº¥y top 3 topics
        top_indices = proba.argsort()[-3:][::-1]
        top_topics = [(model.classes_[i], proba[i]*100) for i in top_indices]
        
        print(f"ğŸ“ Text: {text[:70]}...")
        print(f"ğŸ¯ Dá»± Ä‘oÃ¡n: {prediction}")
        print(f"ğŸ“Š Top 3 topics:")
        for topic, prob in top_topics:
            print(f"   - {topic}: {prob:.2f}%")
        print()

def main():
    print("="*70)
    print("TRAIN MODEL PHÃ‚N LOáº I TOPIC VÄ‚N Báº¢N TIáº¾NG VIá»†T")
    print("="*70)
    
    # Load dataset
    dataset_path = 'data/processed_dataset.csv'
    if not os.path.exists(dataset_path):
        print(f"âŒ KhÃ´ng tÃ¬m tháº¥y file: {dataset_path}")
        print("ğŸ’¡ Cháº¡y download_dataset.py trÆ°á»›c!")
        return
    
    df = load_dataset(dataset_path)
    
    # Preprocess
    df = preprocess_data(df)
    
    # Train
    model, vectorizer, accuracy = train_model(df)
    
    # Save
    save_model(model, vectorizer)
    
    # Test
    test_prediction(model, vectorizer)
    
    print("\n" + "="*70)
    print("âœ… HOÃ€N THÃ€NH BÆ¯á»šC 2.2 - TRAIN MODEL!")
    print("="*70)
    print(f"\nğŸ“Š Káº¿t quáº£:")
    print(f"   - Accuracy: {accuracy*100:.2f}%")
    print(f"   - Model: models/topic_classifier.pkl")
    print(f"   - Vectorizer: models/vectorizer. pkl")
    print(f"\nâ¡ï¸  Tiáº¿p theo: Táº¡o API backend (app.py)")

if __name__ == "__main__":
    main()