import os
import pandas as pd
import re
from pathlib import Path

# Mapping VNTC topics sang 15 topics cá»§a chÃºng ta
TOPIC_MAPPING = {
    'Chinh tri Xa hoi': 'ChÃ­nh trá»‹',
    'Doi song': 'Thá»i sá»±',
    'Khoa hoc': 'Khoa há»c',
    'Kinh doanh': 'Kinh táº¿',
    'Phap luat': 'PhÃ¡p luáº­t',
    'Suc khoe': 'Sá»©c khá»e',
    'The gioi': 'Thá»i sá»±',
    'The thao': 'Thá»ƒ thao',
    'Van hoa': 'VÄƒn hÃ³a',
    'Vi tinh': 'CÃ´ng nghá»‡',
}

def count_words(text):
    """Äáº¿m sá»‘ tá»« trong vÄƒn báº£n tiáº¿ng Viá»‡t"""
    words = text.split()
    return len(words)

def clean_text(text):
    """LÃ m sáº¡ch vÄƒn báº£n"""
    text = re.sub(r'[^\w\sÃ¡Ã áº£Ã£áº¡Äƒáº¯áº±áº³áºµáº·Ã¢áº¥áº§áº©áº«áº­Ã©Ã¨áº»áº½áº¹Ãªáº¿á»á»ƒá»…á»‡Ã­Ã¬á»‰Ä©á»‹Ã³Ã²á»Ãµá»Ã´á»‘á»“á»•á»—á»™Æ¡á»›á»á»Ÿá»¡á»£ÃºÃ¹á»§Å©á»¥Æ°á»©á»«á»­á»¯á»±Ã½á»³á»·á»¹á»µÄ‘ÃÃ€áº¢Ãƒáº Ä‚áº®áº°áº²áº´áº¶Ã‚áº¤áº¦áº¨áºªáº¬Ã‰Ãˆáººáº¼áº¸ÃŠáº¾á»€á»‚á»„á»†ÃÃŒá»ˆÄ¨á»ŠÃ“Ã’á»Ã•á»ŒÃ”á»á»’á»”á»–á»˜Æ á»šá»œá»á» á»¢ÃšÃ™á»¦Å¨á»¤Æ¯á»¨á»ªá»¬á»®á»°Ãá»²á»¶á»¸á»´Ä]', ' ', text)
    text = ' '.join(text.split())
    return text. strip()

def read_vntc_data(vntc_path):
    """Äá»c dá»¯ liá»‡u tá»« VNTC dataset"""
    data = []
    
    # Thá»­ tÃ¬m trong Ver1.1/Train/
    train_path = Path(vntc_path) / 'Data' / '10Topics' / 'Ver1.1' / 'Train'
    
    if not train_path.exists():
        print(f"âŒ KhÃ´ng tÃ¬m tháº¥y thÆ° má»¥c: {train_path}")
        return pd.DataFrame()
    
    print(f"ğŸ“‚ Äang Ä‘á»c tá»«: {train_path}\n")
    
    # Duyá»‡t qua cÃ¡c thÆ° má»¥c topic
    for topic_dir in train_path.iterdir():
        if not topic_dir.is_dir():
            continue
            
        topic_name = topic_dir.name
        print(f"ğŸ“‚ Äang Ä‘á»c topic: {topic_name}")
        count = 0
        
        # Äá»c cÃ¡c file vÄƒn báº£n
        for file_path in topic_dir.glob('*.txt'):
            try:
                # Thá»­ nhiá»u encoding
                text = None
                for encoding in ['utf-16', 'utf-8', 'utf-16-le', 'utf-16-be', 'latin-1']:
                    try:
                        with open(file_path, 'r', encoding=encoding, errors='ignore') as f:
                            text = f.read()
                            if text and len(text.strip()) > 10:  # Äáº£m báº£o cÃ³ ná»™i dung
                                break
                    except:
                        continue
                
                if text and len(text.strip()) > 10:
                    data.append({
                        'text': text.strip(),
                        'original_topic': topic_name
                    })
                    count += 1
                    
            except Exception as e:
                continue
        
        print(f"   âœ… Äá»c Ä‘Æ°á»£c {count} vÄƒn báº£n")
    
    print(f"\nâœ… Tá»•ng cá»™ng Ä‘Ã£ Ä‘á»c {len(data)} vÄƒn báº£n")
    return pd.DataFrame(data)

def process_dataset(vntc_path, output_path, min_words=50, max_words=300, samples_per_topic=50):
    """Xá»­ lÃ½ dataset vÃ  táº¡o file CSV chuáº©n"""
    
    print("ğŸ”„ Báº¯t Ä‘áº§u xá»­ lÃ½ dataset.. .\n")
    
    # Äá»c dá»¯ liá»‡u VNTC
    df = read_vntc_data(vntc_path)
    
    if df.empty:
        print("âŒ KhÃ´ng cÃ³ dá»¯ liá»‡u Ä‘á»ƒ xá»­ lÃ½")
        print("\nğŸ’¡ Kiá»ƒm tra láº¡i cáº¥u trÃºc thÆ° má»¥c:")
        print("   backend/data/VNTC/Data/10Topics/Ver1.1/Train/")
        return None
    
    # LÃ m sáº¡ch vÄƒn báº£n
    print("\nğŸ§¹ Äang lÃ m sáº¡ch vÄƒn báº£n...")
    df['text'] = df['text'].apply(clean_text)
    
    # Loáº¡i bá» vÄƒn báº£n trá»‘ng
    df = df[df['text'].str.len() > 0]
    
    # Äáº¿m sá»‘ tá»«
    df['word_count'] = df['text'].apply(count_words)
    
    print(f"ğŸ“Š PhÃ¢n bá»‘ Ä‘á»™ dÃ i vÄƒn báº£n:")
    print(f"   Min: {df['word_count']. min()} tá»«")
    print(f"   Max: {df['word_count'].max()} tá»«")
    print(f"   Trung bÃ¬nh: {df['word_count'].mean():.0f} tá»«")
    
    # Lá»c theo Ä‘á»™ dÃ i
    df_filtered = df[(df['word_count'] >= min_words) & (df['word_count'] <= max_words)]
    print(f"\nâœ… CÃ²n {len(df_filtered)} vÄƒn báº£n sau khi lá»c Ä‘á»™ dÃ i ({min_words}-{max_words} tá»«)")
    
    if len(df_filtered) == 0:
        print("âŒ KhÃ´ng cÃ²n dá»¯ liá»‡u sau khi lá»c!")
        print(f"ğŸ’¡ Thá»­ giáº£m min_words hoáº·c tÄƒng max_words")
        return None
    
    # Mapping topics
    df_filtered['topic'] = df_filtered['original_topic']. map(TOPIC_MAPPING)
    
    # Loáº¡i bá» cÃ¡c topic khÃ´ng map Ä‘Æ°á»£c
    df_filtered = df_filtered[df_filtered['topic']. notna()]
    
    print(f"\nğŸ“Š PhÃ¢n bá»‘ trÆ°á»›c khi cÃ¢n báº±ng:")
    print(df_filtered['topic'].value_counts())
    
    # CÃ¢n báº±ng dá»¯ liá»‡u
    balanced_data = []
    print(f"\nâš–ï¸  Äang cÃ¢n báº±ng dá»¯ liá»‡u (tá»‘i Ä‘a {samples_per_topic} máº«u/topic):")
    for topic in df_filtered['topic'].unique():
        topic_data = df_filtered[df_filtered['topic'] == topic]
        n_samples = min(len(topic_data), samples_per_topic)
        
        if len(topic_data) >= samples_per_topic:
            topic_data = topic_data.sample(n=samples_per_topic, random_state=42)
        else:
            topic_data = topic_data.sample(frac=1, random_state=42)
            
        balanced_data.append(topic_data)
        print(f"   {topic}: {n_samples} máº«u")
    
    df_balanced = pd.concat(balanced_data, ignore_index=True)
    
    # Chá»‰ giá»¯ láº¡i cá»™t cáº§n thiáº¿t
    df_final = df_balanced[['text', 'topic']]
    
    # Shuffle
    df_final = df_final.sample(frac=1, random_state=42).reset_index(drop=True)
    
    # Táº¡o thÆ° má»¥c náº¿u chÆ°a cÃ³
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    
    # LÆ°u file
    df_final.to_csv(output_path, index=False, encoding='utf-8-sig')
    print(f"\nâœ… ÄÃ£ lÆ°u {len(df_final)} máº«u vÃ o: {output_path}")
    
    # Thá»‘ng kÃª cuá»‘i cÃ¹ng
    print(f"\nğŸ“Š THá»NG KÃŠ DATASET CUá»I CÃ™NG:")
    print(f"Tá»•ng sá»‘ máº«u: {len(df_final)}")
    print(f"\nPhÃ¢n bá»‘ theo topic:")
    print(df_final['topic'].value_counts())
    
    # Hiá»ƒn thá»‹ 2 máº«u ngáº«u nhiÃªn
    print(f"\nğŸ“ MáºªU Dá»® LIá»†U:")
    for i, row in df_final. sample(2). iterrows():
        print(f"\n--- Máº«u {i+1} ---")
        print(f"Topic: {row['topic']}")
        print(f"Text: {row['text'][:150]}...")
    
    return df_final

if __name__ == "__main__":
    # ÄÆ°á»ng dáº«n
    VNTC_PATH = "data/VNTC"
    OUTPUT_PATH = "data/processed_dataset.csv"
    
    # Xá»­ lÃ½
    df = process_dataset(
        vntc_path=VNTC_PATH,
        output_path=OUTPUT_PATH,
        min_words=50,
        max_words=300,
        samples_per_topic=50
    )
    
    if df is not None and not df.empty:
        print("\n" + "="*60)
        print("âœ… HOÃ€N THÃ€NH BÆ¯á»šC 1. 1 & 1.2!")
        print("="*60)
        print(f"\nğŸ’¾ File Ä‘Ã£ lÆ°u táº¡i: {OUTPUT_PATH}")
        print(f"ğŸ“Š Tá»•ng sá»‘ máº«u: {len(df)}")
        print(f"\nâ¡ï¸  Tiáº¿p theo: Train model (BÆ°á»›c 2. 2)")
    else:
        print("\nâŒ Xá»­ lÃ½ tháº¥t báº¡i!")